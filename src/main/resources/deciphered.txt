foundations of security and access control in computing

introduction

access control in computing is motivated by the need to divulge access to information and available computing resources and services to authorized entities only. an entity is a generic term that refers to an active agent capable of initiating or performing a computation of some sort, for example, an end user invoking a command or a program, a programming agent acting on behalf of a user, a running daemon process, a thread of execution, a hosting system, or a networking device,. access modes can be broadly categorized into the ability to read or write information whether in the address space of an executing process, on a secondary storage, or on a network or a peripheral device. this ability can be explicitly expressed by a direct privilege possessed by the acting entity or indirectly through services and computing tasks that the entity is allowed to execute. a purist may pose the question of whether temporarily modifying computer information without having to read it and in a way that leaves its final state unchanged is consistent with the definition of access control. the likely answer is that such activity constitutes a breach to access control and thus it should be guarded against. otherwise, one of the fundamental security tenets of resource availability becomes at risk of being compromised. availability of computing resources has indeed stood as a system and network security concern of its own. furthermore, concurrent access to information that is being modified even temporarily by authorized or unauthorized entities is clearly unacceptable.

evolution of computing systems from single-user to multiuser machines led to the necessity of shielding users and running processes from one another. early protection mechanisms consisted of hardware and operating systems components. subsequently, policy-based authorization subsystems have emerged. controlling access to computing systems is the first defense against disclosing information to unauthorized entities. systems and network access is based on trusted methods for identifying users and programming agents. secure identification is the cornerstone of modern computing security. the advent of networking and distributed computing has led to the proliferation of computing identities. consequently, identity management has evolved as a discipline of its own. the goal is to mitigate the cost of maintaining identity repositories that may exist in the potentially a myriad of systems used by a single enterprise, enforcing consistency and achieving unambiguous mapping of identities representing the same entity or multiple entities collaborating together. automation of inter-enterprise exchanges has further necessitated the drive for federated identity systems. as a result, the scope of an identity is extending well beyond the confines of an organization. with all the associated complexities, a purist perspective seeks a unified model of secure identification. although this is far from being achieved in the real world, any such attempts can only benefit computing security.

real-world examples of access control are abundant and vary according to the needs and policies dictated by the circumstances. at a basic level, users of the same organization are granted access to shared computing resources based on the roles each user is entitled to within the organization. an enterprise may be concerned over losing its competitive edge should its trade secrets become known to its competitors. a financial institution has every need to confine updates in its records to legitimate transactions only and to protect them from exposure to unauthorized individuals and institutions. while a patient medical records may not be of any immediate financial gain, one cannot put a price to their privacy.

access control is evolving from its traditional host-centric paradigm to resources and entities that transact over large networks as wide as the internet. the low-level access-control privileges of the basic read and write of information are now moving up a level higher to include attributes that make up a profile for an entity. these are the elements that mimic real-life user entitlements such as the privilege of having a banking account, having a credit-card number, or being assigned a well-defined role. the processes needed to maintain entity profiling gave rise to what is referred to as identity management, which is indeed a prelude to any access-control mechanism. it is concerned with the trusted methods of managing and exchanging entity entitlements on various computing systems and resource managers. identity management forms the foundation on which access control is based.

in this chapter we introduce the main concepts behind computing security. we begin with a brief overview of security threats. we then elaborate on the major elements of systems security, in particular the aspects surrounding identification and authentication. we highlight the importance of system integrity as a prelude to secure computing. we define what is meant by a security context and discuss its propagation along the units of computing work. subsequently, we delve into the paradigms of access control and outline the elements surrounding trust and assurance, including an introduction to the confinement problem. we conclude with an overview of the major security-design principles.

elements of systems security

a threat by definition is a situation in which any protection mechanisms that govern access to a computing system may become subject to harm. such protection mechanisms are driven by what is called a security policy. we discuss the concept of a security policy in further detail later in the chapter. security threats are analogous to harmful activities that are bound to happen and thus convey the meaning of a pending attack. the latter makes the threat a reality. threats are made possible due to vulnerabilities, also referred to as weaknesses, either in the mechanisms enforcing a particular security policy or in the operational controls of that policy, such as those having to do with configuration parameters. mechanism-related vulnerabilities can be due to design or implementation flaws. dormant vulnerabilities represent a risk. a risk is a measure of potential harm that can be realized when a threat is executed. some of the known categories of security threats include identity theft through masquerading or spoofing, unauthorized access to resources, unauthorized disclosure or modification of data, and denial of service attacks.

security in computing can be viewed as having the following elements:

- secure entity identification, known as authentication and which we refer to as identity establishment;

- confining actions of an established identity to its designated entitlements for services and computing resources, known as resource access control;

- data integrity, confidentiality, and origin authenticity, broadly referred to as data and message security;

- prevention from denial of taking part in a transaction, whether as an initiating or a receiving party, known as nonrepudiation;

- resource availability to thwart against the denial of service attacks.

the fundamental prerequisite for the integrity and soundness of any access-control or other security mechanisms is the secure establishment of identities. for example, the lack of enforcement for secure establishment of identities, makes all attempts to enforce an access policy virtually useless.

identity establishment

identity establishment is concerned with the methods by which a user, a running process, or a thread of execution is securely associated with a legitimate entity. recall that an entity may represent a single user, a group of users, an entire organization, a host system, or some networking device. establishing an identity is the means of concluding that indeed the identity in use corresponds to the entity that it claims to be and thus is said to be authentic. authentication is the secure identification of entities in which a proof of possessing an identity is verified. an entity access to a system is encapsulated in what has become known as an account. engaging in an act of authentication can take place on every attempt to access a controlled computing system, known as a login, when a service from an application is requested, or each time a network access is performed. varying system and network security policies as well as application requirements can dictate the frequency of entity authentication.

the evidence resulting from an established identity is maintained by the computing device in what is referred to as a security context. the latter remains securely attached to every unit of work requested by the corresponding entity. a security context can be exchanged locally across address spaces and may be transmitted over a network embodied in the request with which it is associated.

resource access control

access control, one of the central themes of this book, is also referred to as access authorization or simply authorization. it is about enforcing a predefined access policy. the goal is to confine the actions of an entity only to the services and to the computing resources that it is entitled to. to prevent an access policy from subversion, the controls that enforce it should be foremost capable of binding computing activities to authenticated identities at any fine level of computation, the scope of which may be an entire address space or at the task and thread level. these bindings are known as secure associations. a safe access-control policy prevents leakage of access to unauthorized users directly or indirectly in any state of the underlying computing system. as we have already mentioned, identity establishment is the cornerstone of enforcing any resource access-control policy.

data and message security

although the term data security is generic, its use is mainly concerned with modification detection, origin authenticity, and confidentiality of data that is being processed in-memory, or while residing on a storage medium or during transmission over a computer network, i.e. a message. modification detection or simply data integrity alone is not of value to data security unless it is combined with origin authenticity. an eavesdropping entity may apply the same data-integrity procedures after having intercepted and modified data items, leading the receiving entity to successfully verify the integrity of the breached data but without realizing it was modified. thus, data integrity is usually combined with some form of origin authenticity, ensuring that an integrity-check sum is indeed generated by a legitimate entity, the original source of the data. secure data integrity, one combined with origin authenticity, protects against an unauthorized update of data.

confidentiality is the process of sealing data using a keyed data-scrambling algorithm so that only a designated entity, one with knowledge of the key, is able to apply the reverse transformation and retrieve the data in its original form. the goal is to prevent disclosure of information to unauthorized entities. in a sense, data confidentiality can be used as a mechanism for enforcing access to information. the underlying cost, however, can be prohibitive so that access-control mechanisms are generally not based on data confidentiality. data confidentiality remains a discipline of its own in security. it is selectively applied to sensitive information that when disclosed results in measurable or un-measurable loss of some kind.

nonrepudiation

nonrepudiation of action is the process by which an entity is prevented from denying participation in a transaction either as an initiating or a receiving end. the definition is ultimately applicable to preventing any process or a thread of execution running on behalf of an end user to circumvent the binding of the acting identity with the legitimate entity. although one might argue that nonrepudiation can be accomplished simply by producing audit and transaction trails in a secure and a controllable fashion, a purist would assert that a legally binding nonrepudiation can be very hard to realize. denial may always take one form or another. nevertheless, digital signatures based on public key cryptography and a combination of tamper-proof hardware and software modules have come a long way toward establishing verifiable nonrepudiation services, particularly for initiating entities, i.e. those generating information.

availability

availability addresses the issue of disrupting access to computing resources and services. the type of disruption may range from compromising the functions of a particular service or a system to completely denying access to it. under all circumstances, it is natural for users of any computing service to expect reasonable response times that are comparable to or much better than human-to-human interactions over a telephone line, for instance, to attain the same service.

protecting computing resources from extreme degradation of performance or from deliberate denial of service takes priority over the enforcement of any access-control policy. a denial-of-service attack is one in which a deliberate high volume of bogus requests are sent to a service provider. the intent is to keep legitimate users of the service from using it. an attack as such may bring the service to its threshold capacity, leaving it dedicated to handling malicious requests instead of legitimate ones. the manifestation may result in extremely slow response times and potentially may lead to a complete inhibition of service and ultimately a shutdown due to the exhaustion of runtime resources, such as real or secondary storage or network sockets. powerful attacks as such may further bring down an entire network as wide as the internet to a crawl.

when authorized users are not able to send requests or reach a service, it becomes a secondary concern to have that service enforce an access-control policy. furthermore, the mere existence of the service is entirely threatened. security mechanisms that protect the availability of computing resources guard against various threats of interruption and deliberate actions of slowing down a service or rendering it completely inaccessible. detection and prevention of dos attacks have emerged as among the leading security issues in this era of computing over public networks.

it should be noted that disruptions leading to denial of service may occur at different locations along the path between a client and a server, including the following:

- in the environment of the service here the service is prevented from obtaining resources needed for its proper execution. the attacker focuses on exhausting computing resources of the system in which the service is hosted.

- in the environment of the client the target service is diverted from responding to legitimate requesters and dealing with useful communications by way of attempting to respond to a massive bombardment of random client messages instead.

- along the path between clients and the server the attacker intercepts and then discards useful requests to the service.

cost of security

security in computing, as in anything else, comes with cost and overhead. that cost should be put in perspective with the value of the protected resources. the cost of security has to be proportionate to the losses incurred from any security breaches. insignificant losses do not require significantly higher security costs. measuring potential loss is not a deterministic process; worst-case scenarios therefore are to be assumed. in quantifiable terms, the cost of security should be less than that of entirely replacing a protected computing asset including its data and functionality. being able to quantify various elements of risk enables the development of informed policies that balance the cost of security with the benefits of increased safety. threats have to be considered even in highly secure environments. the probability of ruin in a computing infrastructure, even when relatively low, should be the driving factor behind the provision of security. however, one cannot always put cost to security. invasion of privacy, such as publicly exposing a person medical records, can be detrimental to the person, even when seemingly no quantifiable physical harm is inflicted on the person and the health-care provider.

system integrity: a prelude to security

integrity of information processing was the focus of attention in early stages of the developments in information technology. first, the need for a strict separation between a running control program and user or application programs was addressed even in basic single-user systems. operating systems and hardware advancements such as those pioneered by the ibm system 360 and system 370 family have led to multiuser systems that accommodate a large number of users. the execution of multiple processes addressing a common memory meant that one process must be prevented from overwriting memory locations that are assigned to another process. address-space separation, therefore, had to be maintained in both the virtual storage assigned to a process and the real memory blocks used at runtime. in early ibm systems this problem was addressed with storage-protection keys where a particular process and the storage assigned to it are associated with a unique storage key that must match if the process is allowed to access the storage. any attempt by a process to store data outside of its assigned blocks of memory is recognized by the hardware due to mismatched storage-protection keys.

in ibm system 360 through system 390 and beyond, the control program defining the operating system is isolated from user programs by means of a two-state instruction execution environment. these two states are called supervisor state and problem-program state. a special set of machine instructions including input-output commands to the input-output channels and memory as well as address-space-management instructions are operable only when the system is running in supervisor state. the control program typically executes in supervisor state while user programs always execute in the problem-program state. when an application requests the services of the control program, such as performing input-output, a request is issued to the control program. the control program, executing in the supervisor state, first examines the request to make sure that it will not exceed the logical boundaries of the problem program before the request is executed.

the assurance provided by modern operating systems in isolating concurrently running user applications and control programs is the key to enforcing the security controls that a computer system provides. such isolation is further extended to finer levels of computing units, that of execution threads. the needs for isolation equally apply to the threads executing in a single address space. a classical example of the benefits from well-designed isolation mechanisms are found in the features that are embedded in the control program of the system 390 and its derivative platforms. these mechanisms are extended to cover new software components that are tightly related to the control program. one of these components is the security service layer, which is invoked by various resource managers and also by system components to mediate access to system resour